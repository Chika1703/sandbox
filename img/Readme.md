# Ответы на вопросы по мониторингу и SRE

## 1. Вас пригласили настроить мониторинг на проект. На онбординге вам рассказали, что проект представляет из себя платформу для вычислений с выдачей текстовых отчетов, которые сохраняются на диск. Взаимодействие с платформой осуществляется по протоколу http. Также вам отметили, что вычисления загружают ЦПУ. Какой минимальный набор метрик вы выведите в мониторинг и почему?

Учитывая, что платформа:
- выполняет вычисления (нагрузка на CPU),
- сохраняет текстовые отчёты на диск,
- взаимодействует по HTTP,

**Минимальный набор метрик:**

- **CPU usage** – чтобы отслеживать нагрузку от вычислений и выявлять перегрузки.
- **RAM usage** – чтобы исключить утечки памяти или нехватку ОЗУ.
- **Disk usage и inodes usage** – отчёты сохраняются на диск, важно избежать переполнения.
- **Disk I/O** – важна производительность диска при чтении/записи отчётов.
- **HTTP response codes (2xx, 4xx, 5xx)** – для оценки корректности работы API.
- **HTTP latency** – задержка ответов напрямую влияет на пользовательский опыт.
- **Uptime / доступность HTTP-сервиса** – базовый индикатор работоспособности.

## 2. Менеджер продукта посмотрев на ваши метрики сказал, что ему непонятно что такое RAM/inodes/CPUla. Также он сказал, что хочет понимать, насколько мы выполняем свои обязанности перед клиентами и какое качество обслуживания. Что вы можете ему предложить?

Менеджеру важно видеть **качество обслуживания**, а не технические детали. Предложу:

- **SLA/SLO метрики**:
  - **Процент успешных HTTP-запросов** (например, 2xx/всего).
  - **Доступность сервиса** (аптайм за день/неделю/месяц).
  - **Среднее и 95-й процентиль времени отклика**.
  - **Количество ошибок на 1000 запросов**.

- **Бизнес-метрики (Service Level Indicators, SLI)**:
  - **Количество успешно сгенерированных отчётов**.
  - **Среднее время генерации отчёта**.
  - **Процент отчётов, сохранённых без ошибок**.

Также можно использовать **дашборды** с визуализациями (например, Grafana), где понятным языком и цветами отображается состояние системы.

## 3. Вашей DevOps команде в этом году не выделили финансирование на построение системы сбора логов. Разработчики в свою очередь хотят видеть все ошибки, которые выдают их приложения. Какое решение вы можете предпринять в этой ситуации, чтобы разработчики получали ошибки приложения?

Если нет централизованного лог-сервиса, но нужны ошибки из приложений:

**Решения:**

- Настроить **логирование в файлы** на серверах (например, `/var/log/myapp.log`).
- Использовать **logrotate** для управления размерами логов.
- Настроить **отправку логов по почте или в Telegram** при обнаружении ключевых слов (`ERROR`, `Exception`).
- Простой **агент на bash/python**, который периодически проверяет логи на наличие ошибок и уведомляет.
- Временно использовать **Prometheus + node_exporter + blackbox_exporter** для отслеживания симптомов (500-ошибки, недоступность), если не содержание ошибок.

## 4. Вы, как опытный SRE, сделали мониторинг, куда вывели отображения выполнения SLA=99% по http кодам ответов. Вычисляете этот параметр по следующей формуле: summ_2xx_requests/summ_all_requests. Данный параметр не поднимается выше 70%, но при этом в вашей системе нет кодов ответа 5xx и 4xx. Где у вас ошибка?

Если `SLA = 2xx / all_requests`, но при этом:
- **Нет 4xx**
- **Нет 5xx**
- **SLA < 100% (а именно 70%)**

Значит, **большая часть запросов не получила HTTP-ответ вообще** (например, timeouts, отказ соединения, или запросы не достигли приложения).

**Ошибка** – в расчёт `all_requests` включаются и **неуспешные на уровне сети/соединения/времени**, но **они не фиксируются как 4xx/5xx**, а логируются как ошибки другого рода.

**Решение**:
- Включать в метрики не только коды HTTP, но и:
  - **timeouts**
  - **connection errors**
  - **read/write errors**

## 5. Опишите основные плюсы и минусы pull и push систем мониторинга.

### Pull-модель:
**Плюсы:**
- Простой контроль: система сама опрашивает агенты.
- Безопаснее: не нужно открывать firewall с агентов.
- Удобно настраивать с динамическими целями (Prometheus + сервис-дискавери).

**Минусы:**
- Проблемы с мониторингом узлов за NAT/firewall.
- Скейлится хуже в больших кластерах.

### Push-модель:
**Плюсы:**
- Работает с узлами за NAT/firewall.
- Хороша для метрик из краткоживущих задач (batch jobs, cron).

**Минусы:**
- Труднее контролировать поток данных.
- Возможна потеря данных, если push-сервер недоступен.

## 6. Какие из ниже перечисленных систем относятся к push модели, а какие к pull? А может есть гибридные?

| Система           | Модель     | Комментарий                                      |
|------------------|------------|--------------------------------------------------|
| **Prometheus**   | Pull       | Основная модель — pull, есть push gateway для спец. случаев |
| **TICK (Telegraf, InfluxDB, Chronograf, Kapacitor)** | Push | Telegraf пушит метрики в InfluxDB              |
| **Zabbix**        | Гибрид     | Агент пушит, сервер может сам опрашивать (poll) |
| **VictoriaMetrics** | Гибрид   | Совместим с Prometheus pull, но поддерживает и push |
| **Nagios**        | Pull       | Опрашивает хосты по расписанию (NRPE/SSH/snmp)  |

---

## 7. Склонируйте себе [репозиторий](https://github.com/influxdata/sandbox/tree/master) и запустите TICK-стэк, используя технологии docker и docker-compose.

В виде решения на это упражнение приведите скриншот веб-интерфейса ПО chronograf (`http://localhost:8888`). 

P.S.: если при запуске некоторые контейнеры будут падать с ошибкой - проставьте им режим `Z`, например
`./data:/var/lib:Z`
#


![Inventory](C:\Users\dimak\OneDrive\Desktop\готовое дз\1.jpg)

## 8. Перейдите в веб-интерфейс Chronograf (http://localhost:8888) и откройте вкладку Data explorer.
        
    - Нажмите на кнопку Add a query
    - Изучите вывод интерфейса и выберите БД telegraf.autogen
    - В `measurments` выберите cpu->host->telegraf-getting-started, а в `fields` выберите usage_system. Внизу появится график утилизации cpu.
    - Вверху вы можете увидеть запрос, аналогичный SQL-синтаксису. Поэкспериментируйте с запросом, попробуйте изменить группировку и интервал наблюдений.

Для выполнения задания приведите скриншот с отображением метрик утилизации cpu из веб-интерфейса.
#

![Inventory](C:\Users\dimak\OneDrive\Desktop\готовое дз\2.jpg)



## 9. Изучите список [telegraf inputs](https://github.com/influxdata/telegraf/tree/master/plugins/inputs). 
Добавьте в конфигурацию telegraf следующий плагин - [docker](https://github.com/influxdata/telegraf/tree/master/plugins/inputs/docker):
```
[[inputs.docker]]
  endpoint = "unix:///var/run/docker.sock"
```

Дополнительно вам может потребоваться донастройка контейнера telegraf в `docker-compose.yml` дополнительного volume и 
режима privileged:
```
  telegraf:
    image: telegraf:1.4.0
    privileged: true
    volumes:
      - ./etc/telegraf.conf:/etc/telegraf/telegraf.conf:Z
      - /var/run/docker.sock:/var/run/docker.sock:Z
    links:
      - influxdb
    ports:
      - "8092:8092/udp"
      - "8094:8094"
      - "8125:8125/udp"
```

После настройке перезапустите telegraf, обновите веб интерфейс и приведите скриншотом список `measurments` в 
веб-интерфейсе базы telegraf.autogen . Там должны появиться метрики, связанные с docker.

![Inventory](C:\Users\dimak\OneDrive\Desktop\готовое дз\3.jpg)
